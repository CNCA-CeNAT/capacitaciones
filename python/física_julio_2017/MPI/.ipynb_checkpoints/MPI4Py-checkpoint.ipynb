{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Por qué MPI?\n",
    "## Message Passing Interface\n",
    "- Es el estándar $\\textbf{de facto}$ para computación paralela en infraestructura de HPC (high performance computing)\n",
    "- Tiene una amplia y bien establecida comunidad (desde 1994)\n",
    "- Existe un gran ecosistema de herramientas y aplicaciones construidas sobre MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Paradigma de paso de mensajes\n",
    "- Un programa paralelizado con MPI se descompone en cada uno de sus procesos, que de ahora en adelante llamaremos de manera indistinta $\\textbf{ranks}$\n",
    "- Cada $\\textbf{rank}$ tiene una porción de los datos del programa en su memoria privada\n",
    "- La comunicación entre los $\\textbf{ranks}$ se hace explícita mediante mensajes\n",
    "- Los canales de comunicación siguen el orden FIFO (first-in-first-out), o sea, el primer mensaje que llega es el primero que se procesa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-Program Multiple Data (SPMD)\n",
    "- Todos los procesos ejecutan $\\textbf{el mismo código}$, pero acceden a una porción diferente de los datos\n",
    "- Los procesos se lanzan simultáneamente\n",
    "- La comunicación se da:\n",
    " - Mensajes punto a punto\n",
    " - Operaciones de comunicación colectiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ranks de MPI\n",
    "- Cada uno tiene:\n",
    " - Memoria privada\n",
    " - Un identificador único que corresponde a una numeración secuencial [0->n-1] (donde n es la cantidad de ranks que se lanzan)\n",
    " <img src = \"ranks.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comunicadores\n",
    "- Los comunicadores son estructuras organizacionales en las que se acomodan los ranks para facilitar la comunicación\n",
    "- Todos los ranks están bajo un comunicador global, pero se puede crear otros comunicadores con grupos de ranks específicos\n",
    "<img src= \"groups_comms.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación e instrucciones\n",
    "## Lo primero que hay que hacer para ejecutar mpi en python en el cluster kabré es ejecutar en la consola de bash el siguiente comando:\n",
    "#### module load intelpython/3.5\n",
    "- Para importar la biblioteca utilizamos\n",
    "    from mpi4py import MPI\n",
    "\n",
    "- Para obtener información importante sobre cada rank:\n",
    "    - comm = MPI.COMM_WORLD\n",
    "    - rank = MPI.COMM_WORLD.Get_rank()\n",
    "    - size = MPI.COMM_WORLD.Get_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comunicación punto a punto\n",
    "- Son instrucciones sincronizadas para enviar mensajes desde un rank emisor a uno receptor\n",
    "<img src=\"send.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ejemplo\n",
    "### Vamos a implementar un programa en paralelo llamado \"ping-pong\". El programa debe de enviar un mensaje con un contador que se intercambia entre dos ranks 1000 veces. El rank 1 va a incrementar el contador cada vez que lo recibe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "### Implemente un programa paralelo en python que cree un círculo de ranks. Cada uno genera un número aleatorio entre 0 y 100. El programa luego computa en cada rank la suma de todos los valores haciéndolos circular entre todos los ranks\n",
    "### Para generar números aleatorios utilice from random import randint\n",
    "### La instrucción randint luego puede generar un número aleatorio dentro de un rango [x,y] de esta forma\n",
    "## randint(x,y)\n",
    "<img src = \"ring.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones de comunicación colectiva\n",
    "- Instrucciones que intercambian datos que incluye a todos los ranks dentro de un comunicador\n",
    "- El rank raíz ($\\textbf{root}$) indica la fuente o el destino de la operación\n",
    "    -  $\\textbf{broadcast: }$ Comunucación uno a muchos\n",
    "    \n",
    "    comm.bcast(datos, root = 0)\n",
    "    \n",
    "    - $\\textbf{reduce: }$ Comunicación de muchos a uno\n",
    "    \n",
    "    comm.reduce(data, op=MPI.SUM, root=0)\n",
    "    \n",
    "     - otros ejemplos de operaciones que se pueden hacer con reduce:\n",
    "      - $\\textbf{MPI.MAX}$\n",
    "      - $\\textbf{MPI.MIN}$\n",
    "      - $\\textbf{MPI.PROD}$\n",
    "      \n",
    "    - $\\textbf{comm.Barrier()}$ bloquea la ejecución de los procesos hasta que todos hayan llegado alcanzado ese punto en la ejecución del código. Es una buena herramienta para sincronizar procesos hasta un punto, así se tendrá certeza de que todos los procesos han ejecutado las instrucciones hasta ese punto.\n",
    "    \n",
    "<img src=\"coll.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "### Escriba un programa donde cada rank tenga un número aleatorio y obtenga la suma de todos los valores en los ranks utilizando únicamente bcast y reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - $\\textbf{scatter: }$ Reparte un conjunto de datos entre los distintos ranks\n",
    "   - $\\textbf{gather: }$ Recoge los datos de los distintos ranks y los unifica en una sola estructura\n",
    "   \n",
    "<img src=\"ops.jpeg\">\n",
    "\n",
    "# Ejemplos Gather y Scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MPI + NumPy\n",
    "\n",
    "- $\\textbf{mpi4py}$ provee una forma de comunicar datos como arrays de NumPy entre procesos\n",
    "    - Para hacer esto, se utilizan las mismas funciones que hemos visto antes, pero su primera letra se usa con mayúscula\n",
    "    - Además tienen algunos otros parámetros que hay que especificar, como el buffer que se desea enviar y el buffer para recibir los datos\n",
    " \n",
    "# Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
