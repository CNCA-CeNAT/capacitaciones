{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Por qué MPI?\n",
    "## Message Passing Interface\n",
    "- Es el estándar $\\textbf{de facto}$ para computación paralela en infraestructura de HPC (high performance computing)\n",
    "- Tiene una amplia y bien establecida comunidad (desde 1994)\n",
    "- Existe un gran ecosistema de herramientas y aplicaciones construidas sobre MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas de memoria distribuida\n",
    "\n",
    "### En un sistema de memoria distribuida, cada procesador tiene su propia memoria privada\n",
    "### Una red interconecta a cada uno de los procesadores\n",
    "### La ejecución de los programas se da de manera asíncrona, por lo que la sincronización debe de venir explícitamente por parte del programador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Paradigma de paso de mensajes\n",
    "- Un programa paralelizado con MPI se descompone en cada uno de sus procesos, que de ahora en adelante llamaremos de manera indistinta $\\textbf{ranks}$\n",
    "- Cada proceso tiene una porción de los datos del programa en su memoria privada\n",
    "- La comunicación entre los procesos se hace explícita mediante mensajes definidos por el programador\n",
    "- Los canales de comunicación siguen el orden FIFO (first-in-first-out), o sea, el primer mensaje que llega es el primero que se procesa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Características del paradigma de paso de mensajes\n",
    "- Universalidad: se adecúa a distintos procesadores de distintas arquitecturas conectados a través de una red\n",
    "- Expresividad: es útil para expresar cualquier tipo de algoritmo paralelo\n",
    "- Rendimiento: las implementaciones pueden explotar de manera eficiente el hardware en el que ejecutan\n",
    "- Simplicidad: los principios del paradigma son operaciones de comunicación tradicional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es la Interfaz de Paso de Mensajes (MPI)?\n",
    "\n",
    "- MPI es un estándar para operaciones de paso de mensajes\n",
    "- Las operaciones se expresan como funciones, subrutinas o métodos dependiendo del lenguaje y la implementación\n",
    "- Tiene como meta: \n",
    "    - Permitir la comunicación eficiente\n",
    "    - Traslapar temporalmente las operaciones de comunicación y computación\n",
    "    - Permitir implementaciones que puedan ser utilizadas en ambientes heterogéneos\n",
    "- Algunas de sus implementaciones:\n",
    "    - Open-source: MPICH, OpenMPI\n",
    "    - Propietarias: Cray, IBM, Intel, etc.\n",
    "- Lenguajes:\n",
    "    - C/C++, Fortran, Python, Perl, Ruby, R, Java, CL, Haskell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Procesos (ranks) de MPI\n",
    "- Cada uno tiene:\n",
    " - Memoria privada\n",
    " - Un identificador único que corresponde a una numeración secuencial [0->n-1] (donde n es la cantidad de procesos que se lanzan)\n",
    " <img src = \"ranks.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comunicadores\n",
    "- Los comunicadores son estructuras organizacionales en las que se acomodan los ranks para facilitar la comunicación\n",
    "- Todos los ranks están bajo un comunicador global (COMM_WORLD), pero se puede crear otros comunicadores con grupos de ranks específicos\n",
    "<img src= \"groups_comms.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dentro de un comunicador, a cada proceso se le asigna un identificador único\n",
    "## Sólo los procesos dentro de un mismo comunicador pueden enviarse mensajes entre sí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación e instrucciones\n",
    "## Lo primero que hay que hacer para ejecutar mpi en python en el cluster kabré es ejecutar en la consola de bash el siguiente comando:\n",
    "#### module load intelpython/3.5\n",
    "- Para importar la biblioteca utilizamos\n",
    "    from mpi4py import MPI\n",
    "\n",
    "- Para ejecutar los programas desde consola utilizamos $ \\textbf{mpirun} $\n",
    "\n",
    "# Instrucciones básicas de MPI\n",
    "- Obtener el comunicador global:\n",
    "    - comm = MPI.COMM_WORLD\n",
    "    \n",
    "- Tamaño del comunicador (cuántos procesos tiene):\n",
    "    - size = comm.Get_size()\n",
    " \n",
    "- Obtener el número de rank:\n",
    "    - rank = comm.Get_rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ver ejemplo de código: hola.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comunicación punto a punto\n",
    "- Son instrucciones sincronizadas para enviar mensajes desde un rank emisor a uno receptor\n",
    "<img src=\"send.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ver ejemplo de código: ejemplo_send_rcv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ejercicio\n",
    "### Vamos a implementar un programa en paralelo que sea como un \"ping-pong\". El programa debe de enviar un mensaje con un contador que se intercambia entre dos ranks 1000 veces. El rank 1 va a incrementar el contador cada vez que lo recibe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "### Implemente un programa paralelo en python que cree un círculo de ranks. Cada uno genera un número aleatorio entre 0 y 100. El programa luego computa en cada rank la suma de todos los valores haciéndolos circular entre todos los ranks\n",
    "\n",
    "<img src = \"ring.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemas con comunicación con bloqueo\n",
    "\n",
    "### En el rank 0:\n",
    "     comm.send(dato, dest=1)\n",
    "     otro_dato = comm.recv(source = 1)\n",
    "    \n",
    "### En el rank 1:\n",
    "     comm.send(otro_dato, dest=0)\n",
    "     dato = comm.recv(source = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La comunicación con bloqueo sólo avanza a la siguiente instrucción si la operación de comunicación termina exitosamente\n",
    "- Esto quiere decir que el receive debe de estar listo del otro lado para obtener el dato\n",
    "- Si no se tiene cuidado, podría darse un $\\textbf{deadlock}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"deadlock.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cómo resolver deadlocks?\n",
    "\n",
    "## Reorganizar operaciones send & receive\n",
    "    - Una estrategia podría ser que los ranks pares envíen primero y los impares reciban\n",
    "    \n",
    "## Dejar que MPI se encargue de eso\n",
    "    - A través de la operación sendrecv\n",
    "    \n",
    "## Utilizar comunicación sin bloqueo\n",
    "    - Isend y IRecv\n",
    "\n",
    "# Ver ejemplo ejemplo_sendrecv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones de comunicación colectiva\n",
    "- Instrucciones que intercambian datos que incluye a todos los ranks dentro de un comunicador\n",
    "- El rank raíz ($\\textbf{root}$) indica la fuente o el destino de la operación\n",
    "- Todos los ranks dentro del comunicador deben de llamar a la misma operación colectiva\n",
    "- Estas operaciones pueden ayudar a implementar diferentes patrones de comunicación:\n",
    "    - Uno a muchos\n",
    "    - Muchos a uno\n",
    "    - Muchos a muchos\n",
    "- Pueden servir para diferentes propósitos:\n",
    "    - Traspaso de datos\n",
    "    - Computación colectiva\n",
    "    - Sincronización\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-  $\\textbf{broadcast: }$ Comunucación uno a muchos\n",
    "    \n",
    "    comm.bcast(datos, root = 0)\n",
    "    \n",
    "- $\\textbf{reduce: }$ Comunicación de muchos a uno\n",
    "    \n",
    "    comm.reduce(datos, op=MPI.SUM, root=0)\n",
    "    \n",
    "    \n",
    "     - otros ejemplos de operaciones que se pueden hacer con reduce:\n",
    "      - $\\textbf{MPI.MAX}$\n",
    "      - $\\textbf{MPI.MIN}$\n",
    "      - $\\textbf{MPI.PROD}$\n",
    "      \n",
    "- $\\textbf{comm.Barrier()}$ bloquea la ejecución de los procesos hasta que todos hayan llegado alcanzado ese punto en la ejecución del código. Es una buena herramienta para sincronizar procesos hasta un punto, así se tendrá certeza de que todos los procesos han ejecutado las instrucciones hasta ese punto.\n",
    "    \n",
    "<img src=\"coll.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "### Escriba un programa donde integre numéricamente el área debajo de la curva $ f(x) = \\frac{4}{1+x^2}$ entre 0 y 1 para aproximar el valor de $ \\pi $ utilizando la regla trapezoidal:\n",
    "- Se divide el intervalo de integración\n",
    "- Se le asignan subintervalos a los procesos\n",
    "- Cada proceso calcula una suma parcial\n",
    "- Al final se suman todas las parciales para obtener una aproximación de $\\pi$\n",
    "\n",
    "\n",
    "- El ancho de cada sub-intervalo es de $1/n$ donde n es la cantidad de procesos\n",
    "- La altura del segmento se calcula con la función $f(x)$\n",
    "<img src=\"piFunction.png\" style=\"width: 300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - $\\textbf{scatter: }$ Reparte un conjunto de datos entre los distintos ranks\n",
    "   - $\\textbf{gather: }$ Recoge los datos de los distintos ranks y los unifica en una sola estructura\n",
    "   \n",
    "<img src=\"ops.jpeg\">\n",
    "\n",
    "# Ver ejemplos Gather y Scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MPI + NumPy\n",
    "\n",
    "- $\\textbf{mpi4py}$ provee una forma de comunicar datos como arrays de NumPy entre procesos\n",
    "    - Para hacer esto, se utilizan las mismas funciones que hemos visto antes, pero su primera letra se usa con mayúscula\n",
    "    - Además tienen algunos otros parámetros que hay que especificar, como el buffer que se desea enviar y el buffer para recibir los datos\n",
    " \n",
    "# Ver ejemplo ejemplo_send_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "- Cargue los datos del archivo velocidades.txt en un array de numpy y distribúyalos en 4 procesos.\n",
    "- Aplíquele la siguiente función a cada uno de los datos:\n",
    "$$ f(v) = \\frac{\\pi^2  v  k^2}{2v^{1/2}}$$\n",
    "\n",
    "Con k = 0.667\n",
    "\n",
    "- Posteriormente, recopile todos los datos y grafique el resultado de la función en un sólo proceso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
